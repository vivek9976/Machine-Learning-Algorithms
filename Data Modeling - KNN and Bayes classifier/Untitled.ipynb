{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question 1 part a and b\n",
      "confusion matrix for k=1\n",
      "[[ 93  25]\n",
      " [ 19 200]]\n",
      "accuracy for k=1 0.8694362017804155\n",
      "\n",
      "confusion matrix for k=3\n",
      "[[ 92  26]\n",
      " [  9 210]]\n",
      "accuracy for k=3 0.8961424332344213\n",
      "\n",
      "confusion matrix for k=5\n",
      "[[ 92  26]\n",
      " [ 10 209]]\n",
      "accuracy for k=5 0.8931750741839762\n",
      "\n",
      "max accuracy 0.8961424332344213\n",
      "\n",
      "K=3 has max accuracy\n",
      "question 2 part a and b\n",
      "confusion matrix for k=1\n",
      "[[115   3]\n",
      " [ 13 206]]\n",
      "accuracy for k=1 0.9525222551928784\n",
      "\n",
      "confusion matrix for k=3\n",
      "[[116   2]\n",
      " [ 14 205]]\n",
      "accuracy for k=3 0.9525222551928784\n",
      "\n",
      "confusion matrix for k=5\n",
      "[[116   2]\n",
      " [ 13 206]]\n",
      "accuracy for k=5 0.9554896142433235\n",
      "\n",
      "max accuracy 0.9554896142433235\n",
      "\n",
      "K=5 has max accuracy\n",
      "question 3\n",
      "\n",
      "Mean of class 0:\n",
      " [273.418, 1583169.659, 7779.663, 393.835, 273.183, 843350.275, 53.326, 135.762, 1382.762, 40.073, 0.123, 0.459, 0.592, 0.108, 0.55, 0.523, 0.288, 3.623, 2.057, 1.848, -0.314, -0.115, 0.925]\n",
      "\n",
      "Mean of class 1:\n",
      " [723.656, 1431588.69, 585.967, 54.491, 45.658, 62191.126, 96.236, 130.452, 1480.018, 104.214, 0.385, 0.427, 0.513, 0.02, 0.608, 0.831, 0.608, 2.287, 1.227, 1.318, 0.136, -0.116, 0.543]\n",
      "The confusion matrix for Bayes model\n",
      "[[102  16]\n",
      " [  3 216]]\n",
      "The accuracy for Bayes model\n",
      "0.9436201780415431\n",
      "question 4\n",
      "comparison b/w classifiers based upon classification accuracy\n",
      "               classifier  accuracy (in decimal)\n",
      "0                     KNN                 0.8961\n",
      "1  KNN on normalised data                 0.9556\n",
      "2             Baye method                 0.9436\n"
     ]
    }
   ],
   "source": [
    "#question 1\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "data= pd.read_csv(\"SteelPlateFaults-2class.csv\")\n",
    "\n",
    "# storing column names\n",
    "column = data.columns.to_numpy()\n",
    "# splitting the dataset according to class\n",
    "grouping= data.groupby('Class')\n",
    "\n",
    "# converting the class data into numpy array\n",
    "class0 = grouping.get_group(0).to_numpy()\n",
    "class1 = grouping.get_group(1).to_numpy()\n",
    "\n",
    "# splitting the classes dataset into training and testing sets\n",
    "train0, test0 = train_test_split(class0, test_size=0.30, random_state=42, shuffle=True)\n",
    "train1, test1 = train_test_split(class1, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "# combining the class wise splitted dataset\n",
    "training = np.concatenate((train0, train1), axis=0)\n",
    "testing = np.concatenate((test0, test1), axis=0)\n",
    "\n",
    "# converting the splitted data into dataframe\n",
    "train = pd.DataFrame(training, columns=column)\n",
    "test = pd.DataFrame(testing, columns=column)\n",
    "\n",
    "# saving the data of train and test into csv file\n",
    "train.to_csv('SteelPlateFaults-train.csv')\n",
    "test.to_csv('SteelPlateFaults-test.csv')\n",
    "\n",
    "#applying KNN method to training and testing data\n",
    "train_data= pd.read_csv(\"SteelPlateFaults-train.csv\")\n",
    "test_data=pd.read_csv(\"SteelPlateFaults-test.csv\")\n",
    "train_y=train_data['Class']\n",
    "train_x=train_data.drop(['Class'], axis = 1)\n",
    "test_data= pd.read_csv(\"SteelPlateFaults-test.csv\")\n",
    "test_y=test_data['Class']\n",
    "test_x=test_data.drop(['Class'], axis = 1)\n",
    "\n",
    "#part a and b of question 1\n",
    "print(\"question 1 part a and b\")\n",
    "#for K=1\n",
    "classifier1= KNeighborsClassifier(n_neighbors=1, metric='minkowski', p=2 )  \n",
    "classifier1.fit(train_x, train_y)\n",
    "\n",
    "#Predicting the test set result  \n",
    "y1_pred= classifier1.predict(test_x)  \n",
    "cm1= confusion_matrix(test_y, y1_pred)\n",
    "as1= accuracy_score(test_y, y1_pred)\n",
    "print(\"confusion matrix for k=1\")\n",
    "print(cm1)\n",
    "print(\"accuracy for k=1\",as1)\n",
    "\n",
    "#for K=3\n",
    "classifier3= KNeighborsClassifier(n_neighbors=3, metric='minkowski', p=2 )  \n",
    "classifier3.fit(train_x, train_y)\n",
    "\n",
    "#Predicting the test set result  \n",
    "y3_pred= classifier3.predict(test_x)  \n",
    "cm3= confusion_matrix(test_y, y3_pred)\n",
    "as3= accuracy_score(test_y, y3_pred)\n",
    "print()\n",
    "print(\"confusion matrix for k=3\")\n",
    "print(cm3)\n",
    "print(\"accuracy for k=3\",as3)\n",
    "\n",
    "#for K=5\n",
    "classifier5= KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2 ) \n",
    "classifier5.fit(train_x, train_y)\n",
    "\n",
    "#Predicting the test set result  \n",
    "y5_pred= classifier5.predict(test_x)  \n",
    "cm5= confusion_matrix(test_y, y5_pred)\n",
    "as5= accuracy_score(test_y, y5_pred)\n",
    "print()\n",
    "print(\"confusion matrix for k=5\")\n",
    "print(cm5)\n",
    "print(\"accuracy for k=5\",as5)\n",
    "print()\n",
    "maxaccu=max(as1,as3,as5)\n",
    "print(\"max accuracy\",maxaccu)\n",
    "print()\n",
    "if(maxaccu==as1):\n",
    "    print(\"K=1 has max accuracy\")\n",
    "elif(maxaccu==as3):\n",
    "    print(\"K=3 has max accuracy\")\n",
    "elif(maxaccu==as5):\n",
    "    print(\"K=5 has max accuracy\")\n",
    "    print()\n",
    "#question 2\n",
    "#min max normalization of traning data\n",
    "#normalising train data\n",
    "train_xx=train_x.copy()\n",
    "for col in train_x.columns:\n",
    "    newLowerBound=0\n",
    "    newUpperBound=1\n",
    "    mini = np.min(train_x[col])\n",
    "    maxi = np.max(train_x[col])\n",
    "    ranges = maxi - mini\n",
    "    newRange = newUpperBound - newLowerBound\n",
    "    old = train_x[col].values.tolist()\n",
    "    new = []\n",
    "    \n",
    "    for value in old:\n",
    "        y=((value - mini) / ranges) * newRange + newLowerBound\n",
    "        new.append(y)\n",
    "\n",
    "    train_x[col] = train_x[col].replace(old, new)\n",
    "\n",
    "#normalising test data\n",
    "\n",
    "for col in test_x.columns:\n",
    "    newLowerBound=0\n",
    "    newUpperBound=1\n",
    "    mini = np.min(train_xx[col])\n",
    "    maxi = np.max(train_xx[col])\n",
    "    ranges = maxi - mini\n",
    "    newRange = newUpperBound - newLowerBound\n",
    "    old=test_x[col].values.tolist()\n",
    "    new = []\n",
    "    \n",
    "    for value in old:\n",
    "        y=((value - mini) / ranges) * newRange + newLowerBound\n",
    "        new.append(y)\n",
    "\n",
    "    test_x[col] = test_x[col].replace(old, new)\n",
    "\n",
    "# saving the normalise data of train and test into csv file\n",
    "train_x.to_csv('SteelPlateFaults-train-Normalised.csv')\n",
    "test_x.to_csv('SteelPlateFaults-test-Normalised.csv')\n",
    "\n",
    "#part a and b of question 2\n",
    "print(\"question 2 part a and b\")\n",
    "#for K=1\n",
    "classifier1= KNeighborsClassifier(n_neighbors=1, metric='minkowski', p=2 )  \n",
    "classifier1.fit(train_x, train_y)\n",
    "\n",
    "#Predicting the test set result  \n",
    "y1_pred= classifier1.predict(test_x)  \n",
    "cm1= confusion_matrix(test_y, y1_pred)\n",
    "as1= accuracy_score(test_y, y1_pred)\n",
    "print(\"confusion matrix for k=1\")\n",
    "print(cm1)\n",
    "print(\"accuracy for k=1\",as1)\n",
    "\n",
    "#for K=3\n",
    "classifier3= KNeighborsClassifier(n_neighbors=3, metric='minkowski', p=2 )  \n",
    "classifier3.fit(train_x, train_y)\n",
    "\n",
    "#Predicting the test set result  \n",
    "y3_pred= classifier3.predict(test_x)  \n",
    "cm3= confusion_matrix(test_y, y3_pred)\n",
    "as3= accuracy_score(test_y, y3_pred)\n",
    "print()\n",
    "print(\"confusion matrix for k=3\")\n",
    "print(cm3)\n",
    "print(\"accuracy for k=3\",as3)\n",
    "\n",
    "#for K=5\n",
    "classifier5= KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2 ) \n",
    "classifier5.fit(train_x, train_y)\n",
    "\n",
    "#Predicting the test set result  \n",
    "y5_pred= classifier5.predict(test_x)  \n",
    "cm5= confusion_matrix(test_y, y5_pred)\n",
    "as5= accuracy_score(test_y, y5_pred)\n",
    "print()\n",
    "print(\"confusion matrix for k=5\")\n",
    "print(cm5)\n",
    "print(\"accuracy for k=5\",as5)\n",
    "print()\n",
    "maxaccu=max(as1,as3,as5)\n",
    "print(\"max accuracy\",maxaccu)\n",
    "print()\n",
    "if(maxaccu==as1):\n",
    "    print(\"K=1 has max accuracy\")\n",
    "elif(maxaccu==as3):\n",
    "    print(\"K=3 has max accuracy\")\n",
    "elif(maxaccu==as5):\n",
    "    print(\"K=5 has max accuracy\")\n",
    "#question 3\n",
    "print(\"question 3\")\n",
    "print()\n",
    "# Building a Bayes Classifier\n",
    "train = train.drop(['TypeOfSteel_A300', 'TypeOfSteel_A400', 'Y_Minimum', 'X_Minimum'], axis=1)\n",
    "test= test.drop(['TypeOfSteel_A300', 'TypeOfSteel_A400', 'Y_Minimum', 'X_Minimum'], axis=1)\n",
    "# splitting training dataset into its attributes and labels\n",
    "x_train = train.iloc[:, :-1].values\n",
    "y_train = train.iloc[:, train.shape[1] - 1].values\n",
    "# splitting testing dataset into its attributes and labels\n",
    "x_test = test.iloc[:, :-1].values\n",
    "y_test = test.iloc[:, test.shape[1] - 1].values\n",
    "\n",
    "\n",
    "# sample mean and covariance for class 0\n",
    "train00=pd.DataFrame(train0, columns=column)\n",
    "train00 = train00.drop(['TypeOfSteel_A300', 'TypeOfSteel_A400', 'Y_Minimum', 'X_Minimum'], axis=1)\n",
    "x_train0 = train00.iloc[:, :-1].values\n",
    "y_train0 = train00.iloc[:, train00.shape[1] - 1].values\n",
    "mean0 = np.mean(x_train0, axis=0)\n",
    "cov0 = np.cov(x_train0.T)\n",
    "column_num = [x for x in range(1, 24)]\n",
    "matrix0 = pd.DataFrame(x_train0, columns=column_num)\n",
    "covari0 = pd.DataFrame(matrix0.cov().T.round(decimals=3))\n",
    "covari0.to_csv('covariance_0.csv')\n",
    "print(\"Mean of class 0:\\n\",[round(x, 3) for x in mean0])\n",
    "# sample mean and covariance for class 1\n",
    "train11=pd.DataFrame(train1, columns=column)\n",
    "train11= train11.drop(['TypeOfSteel_A300', 'TypeOfSteel_A400', 'Y_Minimum', 'X_Minimum'], axis=1)\n",
    "x_train1 = train11.iloc[:, :-1].values\n",
    "y_train1 = train11.iloc[:, train11.shape[1] - 1].values\n",
    "mean1 = np.mean(x_train1, axis=0)\n",
    "cov1 = np.cov(x_train1.T)\n",
    "column_num = [x for x in range(1, 24)]\n",
    "matrix1 = pd.DataFrame(x_train1, columns=column_num)\n",
    "covari1 = pd.DataFrame(matrix1.cov().T.round(decimals=3))\n",
    "covari1.to_csv('covariance_1.csv')\n",
    "print()\n",
    "\n",
    "print(\"Mean of class 1:\\n\",[round(x, 3) for x in mean1])\n",
    "# calculating prior probability for each class\n",
    "prior0 = len(y_train0) / len(y_train)\n",
    "prior1 = len(y_train1) / len(y_train)\n",
    "\n",
    "#likelihood function\n",
    "def likelihood(x, mean, cov):\n",
    "    expo = -0.5 * np.dot(np.dot((x - mean).T, np.linalg.inv(cov)), (x - mean))\n",
    "    return (np.exp(expo)) / ((2 * np.pi) ** 11.5 * (np.linalg.det(cov)) ** 0.5)\n",
    "\n",
    "# calculate the likelihood and predicting class \n",
    "yy_pred = []\n",
    "for x in x_test:\n",
    "    likeh0 = likelihood(x, mean0, cov0) * prior0\n",
    "    likeh1 = likelihood(x, mean1, cov1) * prior1\n",
    "    if likeh0 > likeh1:\n",
    "        yy_pred.append(0)\n",
    "\n",
    "    else:\n",
    "        yy_pred.append(1)\n",
    "\n",
    "print(\"The confusion matrix for Bayes model\")\n",
    "print(confusion_matrix(y_test, yy_pred))\n",
    "print(\"The accuracy for Bayes model\")\n",
    "print(accuracy_score(y_test, yy_pred))\n",
    "#question 4\n",
    "print(\"question 4\")\n",
    "# Tabulating the best results of all three classifiers\n",
    "compare = {\"classifier\": [\"KNN\", \"KNN on normalised data\", \"Baye method\"],\n",
    "              \"accuracy (in decimal)\": [0.8961, 0.9556,0.9436]}\n",
    "tt=pd.DataFrame(compare)\n",
    "print(\"comparison b/w classifiers based upon classification accuracy\")\n",
    "print(tt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
